{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/threshold.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/threshold.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "fcompose = lambda *args: compose(*args[::-1])\n",
    "\n",
    "mapdict = lambda **kwargs: map(lambda data: dict(dict((k, f(data)) for k, f in kwargs.items()), **data))\n",
    "\n",
    "## Helper functions\n",
    "@curry\n",
    "def dfassign(df, **kwargs):\n",
    "    return df.assign(**dict(((k, f(df)) for k, f in kwargs.items())))\n",
    "\n",
    "## View the images\n",
    "reshape = lambda arr: arr if len(arr.shape) == 2 else arr[...,0]\n",
    "to_array = lambda image: reshape(numpy.asarray(image.convert(\"L\")))\n",
    "\n",
    "def plt_arrays(arrs):\n",
    "    \"\"\"Plot a set of (n, n) arrays as row column sub plots.\n",
    "    \"\"\"\n",
    "    fig = matplotlib.pyplot.figure(figsize=(7, 7))\n",
    "    N = int(numpy.ceil(numpy.sqrt(len(arrs))))\n",
    "    for i, arr in enumerate(arrs):\n",
    "        ax = fig.add_subplot(N, N, i + 1)\n",
    "        out = ax.imshow(arr, cmap='Greys_r', interpolation='none')\n",
    "        out.axes.get_xaxis().set_visible(False)\n",
    "        out.axes.get_yaxis().set_visible(False)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "## Extract the metadata\n",
    "@curry\n",
    "def crop_image(image, cutoff=960):\n",
    "    \"\"\"Crop the images into the \"upper\" and \"lower\" portions.\n",
    "\n",
    "    Splits the image into the actual image of the microstructure and the embedded metadata.\n",
    "\n",
    "    Args:\n",
    "      image: a PIL image\n",
    "      cutoff: the cutoff height for the upper image\n",
    "\n",
    "    Returns:\n",
    "      {'upper' : upper_image, 'lower': lower_image}\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "               upper=image.crop(box=(0, 0, image.size[0], cutoff)),\n",
    "               lower=image.crop(box=(0, cutoff, image.size[0], image.size[1]))\n",
    "           )\n",
    "\n",
    "def plt_array(arr):\n",
    "    \"\"\"Plot a single 2D array\n",
    "    \"\"\"\n",
    "    ax = matplotlib.pyplot.imshow(arr, cmap='Greys_r', interpolation='none')\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "repair_string = lambda string: float('10' if string == 'mum' else string.replace('pm', ''))\n",
    "\n",
    "scale_pixels = fcompose(\n",
    "    to_array,\n",
    "    lambda data: skimage.measure.label(data, background=0),\n",
    "    skimage.measure.regionprops,\n",
    "    get(1),\n",
    "    lambda data: data.bbox[3] - data.bbox[1],\n",
    ")\n",
    "\n",
    "extract_strings = fcompose(\n",
    "    lambda image: pytesseract.image_to_string(image),\n",
    "    lambda string: string.split(),\n",
    "    get([1, 3, -1]),\n",
    "    lambda data: dict(scale_microns=repair_string(data[0]),\n",
    "                      date=data[1].replace('-', ''),\n",
    "                      time=data[2])\n",
    ")\n",
    "\n",
    "extract_metadata = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('lower'),\n",
    "    lambda image: dict(scale_pixels=scale_pixels(image), **extract_strings(image))\n",
    ")\n",
    "\n",
    "## Rescale the images\n",
    "extract_image = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('upper')\n",
    ")\n",
    "\n",
    "def scale_image(image, rescale_factor):\n",
    "    \"\"\"Scale the image using PIL's thumbnail\n",
    "\n",
    "    thumbnail is an inplace operation so copies are required.\n",
    "\n",
    "    Args:\n",
    "      image: a PIL image\n",
    "      rescale_factor: how much to rescale the image by\n",
    "\n",
    "    Returns:\n",
    "      a new image\n",
    "    \"\"\"\n",
    "    copy_image = image.copy()\n",
    "    copy_image.thumbnail(numpy.array(copy_image.size) * rescale_factor, PIL.Image.ANTIALIAS)\n",
    "    return copy_image\n",
    "\n",
    "get_df = fcompose(\n",
    "    glob.glob,\n",
    "    sorted,\n",
    "    map(\n",
    "        lambda filename: dict(filename=filename,\n",
    "                              **extract_metadata(filename))\n",
    "    ),\n",
    "    list,\n",
    "    pandas.DataFrame,\n",
    "    dfassign(pixel_size=lambda df: df['scale_microns'] / df['scale_pixels']),\n",
    "    dfassign(rescale_factor=lambda df: df['pixel_size'] / max(df['pixel_size'])),\n",
    ")\n",
    "\n",
    "scaled_images = fcompose(\n",
    "    get_df,\n",
    "    lambda df: df.T.to_dict().values(),\n",
    "    mapdict(image=lambda data: extract_image(data['filename'])),\n",
    "    mapdict(scaled_image=lambda data: scale_image(data['image'], data['rescale_factor'])),\n",
    "    list\n",
    ")\n",
    "\n",
    "## Threshold the images into the ferrite and cementite phase\n",
    "threshold_image = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('upper'),\n",
    "    to_array,\n",
    "    lambda data: data > skimage.filters.threshold_otsu(data)\n",
    ")\n",
    "\n",
    "def threshold(filename):\n",
    "\n",
    "    result = dict(filename=filename,\n",
    "                threshold_image=threshold_image(filename),\n",
    "                **extract_metadata(filename))\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    result = threshold(filename)\n",
    "\n",
    "    pickle.dump(result, open(\"{0}-threshold.data\".format(filename_cleaned), 'wb'))\n",
    "    \n",
    "    print(\"{0}-threshold.data\".format(filename_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/min_size.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/min_size.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "## Remove white specs\n",
    "def f_min_size(scale_microns, scale_pixels, island_size=0.2):\n",
    "    return (island_size * scale_pixels / scale_microns)**2\n",
    "\n",
    "def min_size(data):\n",
    "    data['min_size'] = f_min_size(data['scale_microns'], data['scale_pixels'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = min_size(data)\n",
    "    pickle.dump(result, open(\"{0}-min_size.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "    print(\"{0}-min_size.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/clean.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/clean.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "## Binary closing to reveal the Pearlite Phase\n",
    "remove_small_holes = curry(skimage.morphology.remove_small_holes)\n",
    "\n",
    "def clean(data):\n",
    "    data['clean_image'] = ~remove_small_holes(~data['threshold_image'], data['min_size'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    \n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = clean(data)\n",
    "    pickle.dump(result, open(\"{0}-clean.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-clean.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/reveal.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/reveal.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "fcompose = lambda *args: compose(*args[::-1])\n",
    "\n",
    "## Binary closing to reveal the Pearlite Phase\n",
    "closing = curry(flip(skimage.morphology.closing))\n",
    "remove_small_holes = curry(skimage.morphology.remove_small_holes)\n",
    "\n",
    "reveal_pearlite = fcompose(\n",
    "    closing(skimage.morphology.square(5)),\n",
    "    remove_small_holes(min_size=1000)\n",
    ")\n",
    "\n",
    "def reveal(data):\n",
    "    data['pearlite_image'] = reveal_pearlite(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = reveal(data)\n",
    "    pickle.dump(result, open(\"{0}-reveal.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "    print(\"{0}-reveal.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/pearlite.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/pearlite.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "\n",
    "\n",
    "def pearlite(data):\n",
    "    data['pearlite_fraction'] = frac1(data['pearlite_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = pearlite(data)\n",
    "    \n",
    "    pickle.dump(result, open(\"{0}-pearlite.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-pearlite.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/ferrite.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/ferrite.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "frac0 = lambda image: 1 - frac1(image)\n",
    "\n",
    "def ferrite(data):\n",
    "    data['ferrite_fraction'] = frac0(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    \n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = ferrite(data)\n",
    "    pickle.dump(result, open(\"{0}-ferrite.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-ferrite.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/cemmentite.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/cemmentite.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "\n",
    "def cemmentite(data):\n",
    "    data['cemmentite_fraction'] = frac1(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    \n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = cemmentite(data)\n",
    "    pickle.dump(result, open(\"{0}-cemmentite.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-cemmentite.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/save.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/save.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def save(data):\n",
    "    clean_name = data['filename'].split(\"/\")[-1].split(\".\")[0]\n",
    "    file_path = \"{0}.json\".format(clean_name)\n",
    "    filtered_data = {}\n",
    "    filtered_data['filename'] = clean_name\n",
    "    filtered_data['pearlite_fraction'] = data['pearlite_fraction']\n",
    "    filtered_data['ferrite_fraction'] = data['ferrite_fraction']\n",
    "    filtered_data['cemmentite_fraction'] = data['cemmentite_fraction']\n",
    "    with open(file_path, \"w\") as save_file:\n",
    "        save_file.write(json.dumps(filtered_data, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = save(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Code Combined Sumatra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/combined.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/combined.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import dask\n",
    "import json\n",
    "from dask.multiprocessing import get as dak_get\n",
    "\n",
    "from dask.diagnostics import ResourceProfiler, Profiler, CacheProfiler, ProgressBar, visualize\n",
    "from dask import compute\n",
    "from dask.dot import dot_graph\n",
    "\n",
    "from threshold import *\n",
    "from min_size import *\n",
    "from clean import *\n",
    "from reveal import *\n",
    "from pearlite import *\n",
    "from ferrite import *\n",
    "from cemmentite import *\n",
    "from save import *\n",
    "\n",
    "def finalize(saves):\n",
    "    print(\"done.\")\n",
    "    \n",
    "data_path = \"/Users/fyc/Desktop/MRaDS-2017/MRaDS-2017-Demo-Study/data\"\n",
    "\n",
    "dsk = {}\n",
    "files = sorted(glob.glob(\"{0}/*.tif\".format(data_path)))\n",
    "final_saves = []\n",
    "for filename in files:\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    dsk['threshold-{0}'.format(filename_cleaned)] = (threshold, filename)\n",
    "    dsk['min_size-{0}'.format(filename_cleaned)] = (min_size, 'threshold-{0}'.format(filename_cleaned))\n",
    "    dsk['clean-{0}'.format(filename_cleaned)] = (clean, 'min_size-{0}'.format(filename_cleaned))\n",
    "    dsk['reveal-{0}'.format(filename_cleaned)] = (reveal, 'clean-{0}'.format(filename_cleaned))\n",
    "    dsk['pearlite-{0}'.format(filename_cleaned)] = (pearlite, 'reveal-{0}'.format(filename_cleaned))\n",
    "    dsk['ferrite-{0}'.format(filename_cleaned)] = (ferrite, 'pearlite-{0}'.format(filename_cleaned))\n",
    "    dsk['cemmentite-{0}'.format(filename_cleaned)] = (cemmentite, 'ferrite-{0}'.format(filename_cleaned))\n",
    "    dsk['save-{0}'.format(filename_cleaned)] = (save, 'cemmentite-{0}'.format(filename_cleaned))\n",
    "    final_saves.append('save-{0}'.format(filename_cleaned))\n",
    "dsk['finalize'] = (finalize, final_saves)\n",
    "\n",
    "dot_graph(dsk)\n",
    "\n",
    "with ResourceProfiler(0.25) as rprof, Profiler() as prof, CacheProfiler() as cprof, ProgressBar():\n",
    "    dak_get(dsk, 'finalize')\n",
    "\n",
    "visualize([prof, rprof, cprof])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! git add --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master ef32fa2] Run updates...\r\n",
      " 2 files changed, 618 insertions(+), 20 deletions(-)\r\n",
      " rewrite mydask.png (93%)\r\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"Run updates...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/bin/smt\", line 4, in <module>\r\n",
      "    __import__('pkg_resources').require('Sumatra==0.7.dev0')\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 664, in _load_unlocked\r\n",
      "  File \"<frozen importlib._bootstrap>\", line 634, in _load_backward_compatible\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg/pkg_resources/__init__.py\", line 2985, in <module>\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg/pkg_resources/__init__.py\", line 2971, in _call_aside\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg/pkg_resources/__init__.py\", line 2998, in _initialize_master_working_set\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg/pkg_resources/__init__.py\", line 660, in _build_master\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg/pkg_resources/__init__.py\", line 968, in require\r\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/setuptools-27.2.0-py3.5.egg/pkg_resources/__init__.py\", line 854, in resolve\r\n",
      "pkg_resources.DistributionNotFound: The 'jinja2' distribution was not found and is required by Sumatra\r\n"
     ]
    }
   ],
   "source": [
    "! smt run --executable=python --main=code/combined.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
