{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/threshold.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/threshold.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "fcompose = lambda *args: compose(*args[::-1])\n",
    "\n",
    "mapdict = lambda **kwargs: map(lambda data: dict(dict((k, f(data)) for k, f in kwargs.items()), **data))\n",
    "\n",
    "## Helper functions\n",
    "@curry\n",
    "def dfassign(df, **kwargs):\n",
    "    return df.assign(**dict(((k, f(df)) for k, f in kwargs.items())))\n",
    "\n",
    "## View the images\n",
    "reshape = lambda arr: arr if len(arr.shape) == 2 else arr[...,0]\n",
    "to_array = lambda image: reshape(numpy.asarray(image.convert(\"L\")))\n",
    "\n",
    "def plt_arrays(arrs):\n",
    "    \"\"\"Plot a set of (n, n) arrays as row column sub plots.\n",
    "    \"\"\"\n",
    "    fig = matplotlib.pyplot.figure(figsize=(7, 7))\n",
    "    N = int(numpy.ceil(numpy.sqrt(len(arrs))))\n",
    "    for i, arr in enumerate(arrs):\n",
    "        ax = fig.add_subplot(N, N, i + 1)\n",
    "        out = ax.imshow(arr, cmap='Greys_r', interpolation='none')\n",
    "        out.axes.get_xaxis().set_visible(False)\n",
    "        out.axes.get_yaxis().set_visible(False)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "## Extract the metadata\n",
    "@curry\n",
    "def crop_image(image, cutoff=960):\n",
    "    \"\"\"Crop the images into the \"upper\" and \"lower\" portions.\n",
    "\n",
    "    Splits the image into the actual image of the microstructure and the embedded metadata.\n",
    "\n",
    "    Args:\n",
    "      image: a PIL image\n",
    "      cutoff: the cutoff height for the upper image\n",
    "\n",
    "    Returns:\n",
    "      {'upper' : upper_image, 'lower': lower_image}\n",
    "    \"\"\"\n",
    "    return dict(\n",
    "               upper=image.crop(box=(0, 0, image.size[0], cutoff)),\n",
    "               lower=image.crop(box=(0, cutoff, image.size[0], image.size[1]))\n",
    "           )\n",
    "\n",
    "def plt_array(arr):\n",
    "    \"\"\"Plot a single 2D array\n",
    "    \"\"\"\n",
    "    ax = matplotlib.pyplot.imshow(arr, cmap='Greys_r', interpolation='none')\n",
    "    ax.axes.get_xaxis().set_visible(False)\n",
    "    ax.axes.get_yaxis().set_visible(False)\n",
    "    matplotlib.pyplot.tight_layout()\n",
    "    matplotlib.pyplot.show()\n",
    "\n",
    "# NBVAL_IGNORE_OUTPUT\n",
    "repair_string = lambda string: float('10' if string == 'mum' else string.replace('pm', ''))\n",
    "\n",
    "scale_pixels = fcompose(\n",
    "    to_array,\n",
    "    lambda data: skimage.measure.label(data, background=0),\n",
    "    skimage.measure.regionprops,\n",
    "    get(1),\n",
    "    lambda data: data.bbox[3] - data.bbox[1],\n",
    ")\n",
    "\n",
    "extract_strings = fcompose(\n",
    "    lambda image: pytesseract.image_to_string(image),\n",
    "    lambda string: string.split(),\n",
    "    get([1, 3, -1]),\n",
    "    lambda data: dict(scale_microns=repair_string(data[0]),\n",
    "                      date=data[1].replace('-', ''),\n",
    "                      time=data[2])\n",
    ")\n",
    "\n",
    "extract_metadata = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('lower'),\n",
    "    lambda image: dict(scale_pixels=scale_pixels(image), **extract_strings(image))\n",
    ")\n",
    "\n",
    "## Rescale the images\n",
    "extract_image = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('upper')\n",
    ")\n",
    "\n",
    "def scale_image(image, rescale_factor):\n",
    "    \"\"\"Scale the image using PIL's thumbnail\n",
    "\n",
    "    thumbnail is an inplace operation so copies are required.\n",
    "\n",
    "    Args:\n",
    "      image: a PIL image\n",
    "      rescale_factor: how much to rescale the image by\n",
    "\n",
    "    Returns:\n",
    "      a new image\n",
    "    \"\"\"\n",
    "    copy_image = image.copy()\n",
    "    copy_image.thumbnail(numpy.array(copy_image.size) * rescale_factor, PIL.Image.ANTIALIAS)\n",
    "    return copy_image\n",
    "\n",
    "get_df = fcompose(\n",
    "    glob.glob,\n",
    "    sorted,\n",
    "    map(\n",
    "        lambda filename: dict(filename=filename,\n",
    "                              **extract_metadata(filename))\n",
    "    ),\n",
    "    list,\n",
    "    pandas.DataFrame,\n",
    "    dfassign(pixel_size=lambda df: df['scale_microns'] / df['scale_pixels']),\n",
    "    dfassign(rescale_factor=lambda df: df['pixel_size'] / max(df['pixel_size'])),\n",
    ")\n",
    "\n",
    "scaled_images = fcompose(\n",
    "    get_df,\n",
    "    lambda df: df.T.to_dict().values(),\n",
    "    mapdict(image=lambda data: extract_image(data['filename'])),\n",
    "    mapdict(scaled_image=lambda data: scale_image(data['image'], data['rescale_factor'])),\n",
    "    list\n",
    ")\n",
    "\n",
    "## Threshold the images into the ferrite and cementite phase\n",
    "threshold_image = fcompose(\n",
    "    PIL.Image.open,\n",
    "    crop_image,\n",
    "    get('upper'),\n",
    "    to_array,\n",
    "    lambda data: data > skimage.filters.threshold_otsu(data)\n",
    ")\n",
    "\n",
    "def threshold(filename):\n",
    "\n",
    "    result = dict(filename=filename,\n",
    "                threshold_image=threshold_image(filename),\n",
    "                **extract_metadata(filename))\n",
    "    return result\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    result = threshold(filename)\n",
    "\n",
    "    pickle.dump(result, open(\"{0}-threshold.data\".format(filename_cleaned), 'wb'))\n",
    "    \n",
    "    print(\"{0}-threshold.data\".format(filename_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/min_size.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/min_size.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "## Remove white specs\n",
    "def f_min_size(scale_microns, scale_pixels, island_size=0.2):\n",
    "    return (island_size * scale_pixels / scale_microns)**2\n",
    "\n",
    "def min_size(data):\n",
    "    data['min_size'] = f_min_size(data['scale_microns'], data['scale_pixels'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = min_size(data)\n",
    "    pickle.dump(result, open(\"{0}-min_size.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "    print(\"{0}-min_size.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/clean.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/clean.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "## Binary closing to reveal the Pearlite Phase\n",
    "remove_small_holes = curry(skimage.morphology.remove_small_holes)\n",
    "\n",
    "def clean(data):\n",
    "    data['clean_image'] = ~remove_small_holes(~data['threshold_image'], data['min_size'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    \n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = clean(data)\n",
    "    pickle.dump(result, open(\"{0}-clean.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-clean.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/reveal.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/reveal.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "fcompose = lambda *args: compose(*args[::-1])\n",
    "\n",
    "## Binary closing to reveal the Pearlite Phase\n",
    "closing = curry(flip(skimage.morphology.closing))\n",
    "remove_small_holes = curry(skimage.morphology.remove_small_holes)\n",
    "\n",
    "reveal_pearlite = fcompose(\n",
    "    closing(skimage.morphology.square(5)),\n",
    "    remove_small_holes(min_size=1000)\n",
    ")\n",
    "\n",
    "def reveal(data):\n",
    "    data['pearlite_image'] = reveal_pearlite(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = reveal(data)\n",
    "    pickle.dump(result, open(\"{0}-reveal.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "    print(\"{0}-reveal.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/pearlite.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/pearlite.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "\n",
    "\n",
    "def pearlite(data):\n",
    "    data['pearlite_fraction'] = frac1(data['pearlite_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = pearlite(data)\n",
    "    \n",
    "    pickle.dump(result, open(\"{0}-pearlite.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-pearlite.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/ferrite.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/ferrite.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "frac0 = lambda image: 1 - frac1(image)\n",
    "\n",
    "def ferrite(data):\n",
    "    data['ferrite_fraction'] = frac0(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    \n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = ferrite(data)\n",
    "    pickle.dump(result, open(\"{0}-ferrite.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-ferrite.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/cemmentite.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/cemmentite.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import json\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "## Volume function\n",
    "frac1 = lambda image: float(image.sum()) / image.size\n",
    "\n",
    "def cemmentite(data):\n",
    "    data['cemmentite_fraction'] = frac1(data['clean_image'])\n",
    "    return data\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "    \n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = cemmentite(data)\n",
    "    pickle.dump(result, open(\"{0}-cemmentite.data\".format(filename_cleaned), 'wb'))\n",
    "\n",
    "\n",
    "    print(\"{0}-cemmentite.data\".format(filename_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/save.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/save.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "import sys\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "def save(data):\n",
    "    clean_name = data['filename'].split(\"/\")[-1].split(\".\")[0]\n",
    "    file_path = \"{0}.json\".format(clean_name)\n",
    "    filtered_data = {}\n",
    "    filtered_data['filename'] = clean_name\n",
    "    filtered_data['pearlite_fraction'] = data['pearlite_fraction']\n",
    "    filtered_data['ferrite_fraction'] = data['ferrite_fraction']\n",
    "    filtered_data['cemmentite_fraction'] = data['cemmentite_fraction']\n",
    "    with open(file_path, \"w\") as save_file:\n",
    "        save_file.write(json.dumps(filtered_data, sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filename = sys.argv[1]\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    filename_cleaned = \"-\".join(filename_cleaned.split(\"-\")[0:-1])\n",
    "\n",
    "    data = None\n",
    "    with open(filename, \"r\") as intermediate:\n",
    "        data = pickle.load(intermediate)\n",
    "\n",
    "    result = save(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Study Code Combined Sumatra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting code/combined.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile code/combined.py\n",
    "import glob\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "import scipy.ndimage\n",
    "import pytesseract\n",
    "import PIL.Image\n",
    "from toolz.curried import map, pipe, compose, get, do, curry, count, pluck, juxt, flip\n",
    "import pandas\n",
    "import skimage\n",
    "import skimage.measure\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "import dask\n",
    "import json\n",
    "from dask.multiprocessing import get as dak_get\n",
    "\n",
    "from dask.diagnostics import ResourceProfiler, Profiler, CacheProfiler, ProgressBar, visualize\n",
    "from dask import compute\n",
    "from dask.dot import dot_graph\n",
    "\n",
    "from threshold import *\n",
    "from min_size import *\n",
    "from clean import *\n",
    "from reveal import *\n",
    "from pearlite import *\n",
    "from ferrite import *\n",
    "from cemmentite import *\n",
    "from save import *\n",
    "\n",
    "def finalize(saves):\n",
    "    print(\"done.\")\n",
    "    \n",
    "data_path = \"/Users/fyc/Desktop/MRaDS-2017/MRaDS-2017-Demo-Study/data\"\n",
    "\n",
    "dsk = {}\n",
    "files = sorted(glob.glob(\"{0}/*.tif\".format(data_path)))\n",
    "final_saves = []\n",
    "for filename in files:\n",
    "    filename_cleaned = filename.split(\"/\")[-1].split(\".\")[0]\n",
    "    dsk['threshold-{0}'.format(filename_cleaned)] = (threshold, filename)\n",
    "    dsk['min_size-{0}'.format(filename_cleaned)] = (min_size, 'threshold-{0}'.format(filename_cleaned))\n",
    "    dsk['clean-{0}'.format(filename_cleaned)] = (clean, 'min_size-{0}'.format(filename_cleaned))\n",
    "    dsk['reveal-{0}'.format(filename_cleaned)] = (reveal, 'clean-{0}'.format(filename_cleaned))\n",
    "    dsk['pearlite-{0}'.format(filename_cleaned)] = (pearlite, 'reveal-{0}'.format(filename_cleaned))\n",
    "    dsk['ferrite-{0}'.format(filename_cleaned)] = (ferrite, 'pearlite-{0}'.format(filename_cleaned))\n",
    "    dsk['cemmentite-{0}'.format(filename_cleaned)] = (cemmentite, 'ferrite-{0}'.format(filename_cleaned))\n",
    "    dsk['save-{0}'.format(filename_cleaned)] = (save, 'cemmentite-{0}'.format(filename_cleaned))\n",
    "    final_saves.append('save-{0}'.format(filename_cleaned))\n",
    "dsk['finalize'] = (finalize, final_saves)\n",
    "\n",
    "dot_graph(dsk)\n",
    "\n",
    "with ResourceProfiler(0.25) as rprof, Profiler() as prof, CacheProfiler() as cprof, ProgressBar():\n",
    "    dak_get(dsk, 'finalize')\n",
    "\n",
    "visualize([prof, rprof, cprof])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! git add --all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master 49283fc] Run updates...\r\n",
      " 2 files changed, 765 insertions(+), 1363 deletions(-)\r\n",
      " rewrite mydask.png (93%)\r\n",
      " rewrite sumatra.ipynb (69%)\r\n"
     ]
    }
   ],
   "source": [
    "! git commit -m \"Run updates...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple versions found, using /Users/fyc/anaconda2/envs/demo-3.5/bin/python. If you wish to use a different version, please specify it explicitly\n",
      "Multiple versions found, using /Users/fyc/anaconda2/envs/demo-3.5/bin/python. If you wish to use a different version, please specify it explicitly\n",
      "b'\\r[                                        ] | 0% Completed |  0.0s\\r[                                        ] | 0% Completed |  0.1s\\r[                                        ] | 0% Completed |  0.2s\\r[                                        ] | 0% Completed |  0.3s\\r[                                        ] | 0% Completed |  0.4s\\r[                                        ] | 0% Completed |  0.5s\\r[                                        ] | 0% Completed |  0.6s\\r[                                        ] | 0% Completed |  0.7s\\r[                                        ] | 0% Completed |  0.8s\\r[                                        ] | 0% Completed |  0.9s\\r[                                        ] | 0% Completed |  1.0s\\r[                                        ] | 0% Completed |  1.1s\\r[                                        ] | 0% Completed |  1.2s\\r[                                        ] | 0% Completed |  1.3s\\r[                                        ] | 0% Completed |  1.4s\\r[                                        ] | 0% Completed |  1.5s\\r[#####################                   ] | 52% Completed |  1.6s\\r[#########################               ] | 63% Completed |  1.8s\\r[#################################       ] | 84% Completed |  1.9s\\r[#################################       ] | 84% Completed |  2.0s\\r[#################################       ] | 84% Completed |  2.1s\\r[#################################       ] | 84% Completed |  2.2s\\r[#################################       ] | 84% Completed |  2.3s\\r[########################################] | 100% Completed |  2.4s\\n'b'done.\\n'Record label for this run: '20170926-173052'\n",
      "No data produced.\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/projects.py\", line 239, in add_record\n",
      "    self.record_store.save(self.name, record)\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/recordstore/django_store/__init__.py\", line 188, in save\n",
      "    db_record = self._get_db_record(project_name, record)\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/recordstore/django_store/__init__.py\", line 157, in _get_db_record\n",
      "    models = self._get_models()\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/recordstore/django_store/__init__.py\", line 137, in _get_models\n",
      "    db_config.configure()\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/recordstore/django_store/__init__.py\", line 102, in configure\n",
      "    self._create_databases()\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/recordstore/django_store/__init__.py\", line 93, in _create_databases\n",
      "    management.call_command('syncdb', database=label, verbosity=0)\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/Django-1.11.5-py3.5.egg/django/core/management/__init__.py\", line 106, in call_command\n",
      "    app_name = get_commands()[command_name]\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/Django-1.11.5-py3.5.egg/django/core/management/__init__.py\", line 72, in get_commands\n",
      "    for app_config in reversed(list(apps.get_app_configs())):\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/Django-1.11.5-py3.5.egg/django/apps/registry.py\", line 138, in get_app_configs\n",
      "    self.check_apps_ready()\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/lib/python3.5/site-packages/Django-1.11.5-py3.5.egg/django/apps/registry.py\", line 125, in check_apps_ready\n",
      "    raise AppRegistryNotReady(\"Apps aren't loaded yet.\")\n",
      "django.core.exceptions.AppRegistryNotReady: Apps aren't loaded yet.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/fyc/anaconda2/envs/demo-3.5/bin/smt\", line 6, in <module>\n",
      "    exec(compile(open(__file__).read(), __file__, 'exec'))\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/bin/smt\", line 31, in <module>\n",
      "    main(sys.argv[2:])\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/commands.py\", line 382, in run\n",
      "    version=args.version or 'current')\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/projects.py\", line 200, in launch\n",
      "    self.add_record(record)\n",
      "  File \"/Users/fyc/Desktop/MRaDS-2017/corr-sumatra/sumatra/projects.py\", line 244, in add_record\n",
      "    print(self.record_store.server_url)\n",
      "AttributeError: 'DjangoRecordStore' object has no attribute 'server_url'\n"
     ]
    }
   ],
   "source": [
    "! smt run --executable=python --main=code/combined.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
